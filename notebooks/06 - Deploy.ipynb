{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6T-U2o2vJ_s-",
        "outputId": "8f1698b4-3984-4ca2-badb-8fe423fecda6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: asttokens==2.2.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: black==22.10.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 3)) (22.10.0)\n",
            "Requirement already satisfied: blis==0.7.9 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 4)) (0.7.9)\n",
            "Requirement already satisfied: catalogue==2.0.8 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 5)) (2.0.8)\n",
            "Requirement already satisfied: certifi==2022.9.24 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 6)) (2022.9.24)\n",
            "Requirement already satisfied: charset-normalizer==2.1.1 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 7)) (2.1.1)\n",
            "Requirement already satisfied: click==8.1.3 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 8)) (8.1.3)\n",
            "Requirement already satisfied: colorama==0.4.6 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 9)) (0.4.6)\n",
            "Requirement already satisfied: confection==0.0.3 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 10)) (0.0.3)\n",
            "Requirement already satisfied: contourpy==1.0.6 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 11)) (1.0.6)\n",
            "Requirement already satisfied: cycler==0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 12)) (0.11.0)\n",
            "Requirement already satisfied: cymem==2.0.7 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 13)) (2.0.7)\n",
            "Requirement already satisfied: debugpy==1.6.4 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 14)) (1.6.4)\n",
            "Requirement already satisfied: decorator==5.1.1 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 15)) (5.1.1)\n",
            "Requirement already satisfied: entrypoints==0.4 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 16)) (0.4)\n",
            "Requirement already satisfied: executing==1.2.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 17)) (1.2.0)\n",
            "Requirement already satisfied: filelock==3.8.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 18)) (3.8.0)\n",
            "Requirement already satisfied: fonttools==4.38.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 19)) (4.38.0)\n",
            "Requirement already satisfied: gensim==4.2.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 20)) (4.2.0)\n",
            "Requirement already satisfied: huggingface-hub==0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 21)) (0.11.0)\n",
            "Requirement already satisfied: idna==3.4 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 22)) (3.4)\n",
            "Requirement already satisfied: ipykernel==6.17.1 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 23)) (6.17.1)\n",
            "Requirement already satisfied: ipython==8.7.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 24)) (8.7.0)\n",
            "Requirement already satisfied: jedi==0.18.2 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 25)) (0.18.2)\n",
            "Requirement already satisfied: Jinja2==3.1.2 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 26)) (3.1.2)\n",
            "Requirement already satisfied: joblib==1.2.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 27)) (1.2.0)\n",
            "Requirement already satisfied: jupyter_client==7.4.7 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 28)) (7.4.7)\n",
            "Requirement already satisfied: jupyter_core==5.1.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 29)) (5.1.0)\n",
            "Requirement already satisfied: kiwisolver==1.4.4 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 30)) (1.4.4)\n",
            "Requirement already satisfied: langcodes==3.3.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 31)) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe==2.1.1 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 32)) (2.1.1)\n",
            "Requirement already satisfied: matplotlib==3.6.2 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 33)) (3.6.2)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 34)) (0.1.6)\n",
            "Requirement already satisfied: murmurhash==1.0.9 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 35)) (1.0.9)\n",
            "Requirement already satisfied: mypy-extensions==0.4.3 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 36)) (0.4.3)\n",
            "Requirement already satisfied: nest-asyncio==1.5.6 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 37)) (1.5.6)\n",
            "Requirement already satisfied: nltk==3.7 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 38)) (3.7)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 39)) (1.23.5)\n",
            "Requirement already satisfied: packaging==21.3 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 40)) (21.3)\n",
            "Requirement already satisfied: pandas==1.5.2 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 41)) (1.5.2)\n",
            "Requirement already satisfied: parso==0.8.3 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 42)) (0.8.3)\n",
            "Requirement already satisfied: pathspec==0.10.2 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 43)) (0.10.2)\n",
            "Requirement already satisfied: pathy==0.8.1 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 44)) (0.8.1)\n",
            "Requirement already satisfied: pexpect==4.8.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 45)) (4.8.0)\n",
            "Requirement already satisfied: pickleshare==0.7.5 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 46)) (0.7.5)\n",
            "Requirement already satisfied: Pillow==9.3.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 47)) (9.3.0)\n",
            "Requirement already satisfied: platformdirs==2.5.4 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 48)) (2.5.4)\n",
            "Requirement already satisfied: preshed==3.0.8 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 49)) (3.0.8)\n",
            "Requirement already satisfied: prompt-toolkit==3.0.33 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 50)) (3.0.33)\n",
            "Requirement already satisfied: psutil==5.9.4 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 51)) (5.9.4)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 52)) (0.7.0)\n",
            "Requirement already satisfied: pure-eval==0.2.2 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 53)) (0.2.2)\n",
            "Requirement already satisfied: pydantic==1.10.2 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 54)) (1.10.2)\n",
            "Requirement already satisfied: Pygments==2.13.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 55)) (2.13.0)\n",
            "Requirement already satisfied: pyparsing==3.0.9 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 56)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 57)) (2.8.2)\n",
            "Requirement already satisfied: pytz==2022.6 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 58)) (2022.6)\n",
            "Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 59)) (6.0)\n",
            "Requirement already satisfied: pyzmq==24.0.1 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 60)) (24.0.1)\n",
            "Requirement already satisfied: regex==2022.10.31 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 61)) (2022.10.31)\n",
            "Requirement already satisfied: requests==2.28.1 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 62)) (2.28.1)\n",
            "Requirement already satisfied: scikit-learn==1.1.3 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 63)) (1.1.3)\n",
            "Requirement already satisfied: scipy==1.9.3 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 64)) (1.9.3)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 65)) (1.16.0)\n",
            "Requirement already satisfied: smart-open==5.2.1 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 66)) (5.2.1)\n",
            "Requirement already satisfied: spacy==3.4.3 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 67)) (3.4.3)\n",
            "Requirement already satisfied: spacy-legacy==3.0.10 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 68)) (3.0.10)\n",
            "Requirement already satisfied: spacy-loggers==1.0.3 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 69)) (1.0.3)\n",
            "Requirement already satisfied: srsly==2.4.5 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 70)) (2.4.5)\n",
            "Requirement already satisfied: stack-data==0.6.2 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 71)) (0.6.2)\n",
            "Requirement already satisfied: thinc==8.1.5 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 72)) (8.1.5)\n",
            "Requirement already satisfied: threadpoolctl==3.1.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 73)) (3.1.0)\n",
            "Requirement already satisfied: tokenizers==0.13.2 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 74)) (0.13.2)\n",
            "Requirement already satisfied: tomli==2.0.1 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 75)) (2.0.1)\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 76)) (1.13.0)\n",
            "Requirement already satisfied: tornado==6.2 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 77)) (6.2)\n",
            "Requirement already satisfied: tqdm==4.64.1 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 78)) (4.64.1)\n",
            "Requirement already satisfied: traitlets==5.6.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 79)) (5.6.0)\n",
            "Requirement already satisfied: transformers==4.24.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 80)) (4.24.0)\n",
            "Requirement already satisfied: typer==0.7.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 81)) (0.7.0)\n",
            "Requirement already satisfied: typing_extensions==4.4.0 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 82)) (4.4.0)\n",
            "Requirement already satisfied: urllib3==1.26.12 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 83)) (1.26.12)\n",
            "Requirement already satisfied: wasabi==0.10.1 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 84)) (0.10.1)\n",
            "Requirement already satisfied: wcwidth==0.2.5 in /usr/local/lib/python3.8/dist-packages (from -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 85)) (0.2.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy==3.4.3->-r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 67)) (57.4.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->-r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 76)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->-r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 76)) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->-r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 76)) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->-r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 76)) (11.10.3.66)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->-r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt (line 76)) (0.38.4)\n"
          ]
        }
      ],
      "source": [
        "# Install requirement packages.\n",
        "%pip install -r https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Qze6drD8J_tB",
        "outputId": "0520b8d0-072f-474f-fe17-da3a6d19a9f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Required packages installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Required packages.\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import logging\n",
        "import string\n",
        "\n",
        "from io import BytesIO\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
        "\n",
        "RANDOM_SEED = 19730115\n",
        "rng = np.random.RandomState(RANDOM_SEED)\n",
        "\n",
        "print(\"Required packages installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vAPtJ9V0J_tD"
      },
      "outputs": [],
      "source": [
        "# Script constants.\n",
        "DATA_ROOT_FOLDER = os.path.join(\n",
        "    os.path.dirname(os.path.dirname(os.path.abspath(__name__))), \"data\"\n",
        ")\n",
        "DATA_PROCESSED_FOLDER = os.path.join(DATA_ROOT_FOLDER, \"processed\")\n",
        "DATA_EMBEDDINGS_FOLDER = os.path.join(DATA_ROOT_FOLDER, \"embeddings\")\n",
        "URL_SOURCE = \"https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/data/raw/buscape.csv\"\n",
        "RANDOM_SEED = 19730115\n",
        "NUMBER_OF_WORDS = 50\n",
        "rng = np.random.RandomState(RANDOM_SEED)\n",
        "\n",
        "EMBEDDING_NAMES = [\n",
        "    [\"word2vec\", \"cbow_s50\"],\n",
        "    [\"word2vec\", \"skip_s50\"],\n",
        "    [\"fasttext\", \"cbow_s50\"],\n",
        "    [\"fasttext\", \"skip_s50\"],\n",
        "    [\"glove\", \"glove_s50\"],\n",
        "    [\"wang2vec\", \"cbow_s50\"],\n",
        "    [\"wang2vec\", \"skip_s50\"],\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "juGfaK3iJ_tE"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Common Functions.\n",
        "def load_dataset(path, frac=None):\n",
        "    \"\"\"Get the data from csv file\n",
        "\n",
        "    Args:\n",
        "        path(str): the file complete path.\n",
        "\n",
        "    Returns:\n",
        "        dataframe: A pandas dataframe.\n",
        "    \"\"\"\n",
        "    dataset = pd.read_csv(path)\n",
        "\n",
        "    if frac:\n",
        "        dataset = dataset.groupby(\"polarity\", group_keys=False).apply(\n",
        "            lambda x: x.sample(frac=0.4, random_state=rng)\n",
        "        )\n",
        "        dataset.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def load_pickle_dataset(path):\n",
        "    \"\"\"Read pickle.\n",
        "\n",
        "    Args:\n",
        "        path (str): The full dataset file.\n",
        "\n",
        "    Returns:\n",
        "        features(array) and target(array):\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the features and target variable.\n",
        "    data = pd.read_pickle(path)\n",
        "    features, target = data.iloc[:, 1:-1].values, data.iloc[:, -1].values\n",
        "\n",
        "    return features, target\n",
        "\n",
        "\n",
        "def count_word(text):\n",
        "    \"\"\"Word counter.\"\"\"\n",
        "    return len(text.split())\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Make text lowercase, remove text in square brackets, remove punctuation and\n",
        "        remove words containing numbers.\n",
        "\n",
        "    Args:\n",
        "        text(str): string text to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "        A cleaned text\n",
        "\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(\"\\[.*?\\]\", \"\", text)\n",
        "    text = re.sub(\"[%s]\" % re.escape(string.punctuation), \"\", text)\n",
        "    text = re.sub(\"\\w*\\d\\w*\", \"\", text)\n",
        "    text = re.sub('[``\"\"...]', \"\", text)\n",
        "    text = re.sub(\"\\n\", \" \", text)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def text_to_vector(model, dataset):\n",
        "\n",
        "    vectorizer = model.fit_transform(dataset[\"review_text_cleaned_no_stopwords\"])\n",
        "    vocab = model.get_feature_names_out()\n",
        "    dtm = pd.DataFrame(vectorizer.toarray(), columns=vocab)\n",
        "    dtm.index = dataset.index\n",
        "    return (\n",
        "        pd.concat(\n",
        "            [dataset[[\"original_index\"]], dtm, dataset[[\"polarity\"]]],\n",
        "            axis=1,\n",
        "        ),\n",
        "        vocab,\n",
        "    )\n",
        "\n",
        "\n",
        "# def text_to_bert(text)\n",
        "def text_to_embedding(text, model, vectorizer=None, vocab=None, size=50):\n",
        "    if not vectorizer:\n",
        "        raise Exception(\"The vectorizer parameter must not be None\")\n",
        "\n",
        "    transformed = vectorizer.transform(text)\n",
        "    vectorized = pd.DataFrame(\n",
        "        transformed.toarray(), columns=vectorizer.get_feature_names_out()\n",
        "    )\n",
        "\n",
        "    embeedings = pd.DataFrame()\n",
        "    for i in range(vectorized.shape[0]):\n",
        "        sentence = np.zeros(size)\n",
        "        for word in vocab[vectorized.iloc[i, :] > 0]:\n",
        "            if model.get_index(word, default=-1) != -1:\n",
        "                sentence = sentence + model.get_vector(word)\n",
        "            else:\n",
        "                print(\"Out of Vocabulary\")\n",
        "\n",
        "        embeedings = pd.concat([embeedings, pd.DataFrame([sentence])])\n",
        "\n",
        "    return embeedings\n",
        "\n",
        "def download_extract(model, architecture):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    url = f\"http://143.107.183.175:22980/download.php?file=embeddings/{model}/{architecture}.zip\"\n",
        "    out_folder_path = os.path.join(DATA_EMBEDDINGS_FOLDER, model)\n",
        "    out_file_path = os.path.join(out_folder_path, architecture)\n",
        "    print(f\"Downloading: {model}_{architecture}\")\n",
        "    if not os.path.exists(out_file_path):\n",
        "        with urlopen(url) as response:\n",
        "            with ZipFile(BytesIO(response.read())) as in_file_zip:\n",
        "                in_file_zip.extractall(out_folder_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and prepare dataset"
      ],
      "metadata": {
        "id": "naiVO-PcOZ6J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0WFmrKSYJ_tG",
        "outputId": "f69e4bd4-47c5-4083-c693-da5e429b0b0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reviews dataset loaded from https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/data/raw/buscape.csv.\n",
            "The reviews dataset has 29451 rows and 8 cols.\n"
          ]
        }
      ],
      "source": [
        "reviews = load_dataset(URL_SOURCE, frac=0.4)\n",
        "print(f\"The reviews dataset loaded from {URL_SOURCE}.\")\n",
        "print(f\"The reviews dataset has {reviews.shape[0]} rows and {reviews.shape[1]} cols.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qj-SSznvJ_tG",
        "outputId": "29916b26-478c-49e2-b9bc-c4066accccdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-7b51556cd60f>:7: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  reviews.loc[:, [\"review_text_cleaned_len\"]] = reviews[\"review_text_cleaned\"].apply(\n",
            "<ipython-input-26-7b51556cd60f>:14: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  reviews.loc[:, [\"review_text_cleaned_len_no_stopwords\"]] = reviews[\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   original_index                                        review_text  \\\n",
              "0        0_430974  Dá muito problema no encanamento e faz muito b...   \n",
              "1         0_43825  poow galera aki naum da para upa direito por q...   \n",
              "2        0_401867  Não gostei deste aparelho. Não dá pra deixar o...   \n",
              "3        9_159935  Muito ruim a adega acd 28 pois o compartimento...   \n",
              "4  minus_1_393969  A tv LCD é muito boa e economiza espaço dentro...   \n",
              "\n",
              "                                 review_text_cleaned  review_text_cleaned_len  \\\n",
              "0  dá muito problema no encanamento e faz muito b...                        9   \n",
              "1  poow galera aki naum da para upa direito por q...                       28   \n",
              "2  não gostei deste aparelho não dá pra deixar os...                       24   \n",
              "3  muito ruim a adega acd  pois o compartimento i...                       79   \n",
              "4  a tv lcd é muito boa e economiza espaço dentro...                       23   \n",
              "\n",
              "                    review_text_cleaned_no_stopwords  \\\n",
              "0                dá problema encanamento faz barulho   \n",
              "1  poow galera aki naum upa direito muita gente f...   \n",
              "2  gostei deste aparelho dá pra deixar aplicativo...   \n",
              "3  ruim adega acd pois compartimento inferior alt...   \n",
              "4  tv lcd boa economiza espaço dentro casa gostei...   \n",
              "\n",
              "   review_text_cleaned_len_no_stopwords  polarity  \n",
              "0                                     5        -1  \n",
              "1                                    14        -1  \n",
              "2                                    16        -1  \n",
              "3                                    46        -1  \n",
              "4                                    13        -1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48c05fd4-11a4-480f-ab59-4ec43c27664c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_index</th>\n",
              "      <th>review_text</th>\n",
              "      <th>review_text_cleaned</th>\n",
              "      <th>review_text_cleaned_len</th>\n",
              "      <th>review_text_cleaned_no_stopwords</th>\n",
              "      <th>review_text_cleaned_len_no_stopwords</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0_430974</td>\n",
              "      <td>Dá muito problema no encanamento e faz muito b...</td>\n",
              "      <td>dá muito problema no encanamento e faz muito b...</td>\n",
              "      <td>9</td>\n",
              "      <td>dá problema encanamento faz barulho</td>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0_43825</td>\n",
              "      <td>poow galera aki naum da para upa direito por q...</td>\n",
              "      <td>poow galera aki naum da para upa direito por q...</td>\n",
              "      <td>28</td>\n",
              "      <td>poow galera aki naum upa direito muita gente f...</td>\n",
              "      <td>14</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0_401867</td>\n",
              "      <td>Não gostei deste aparelho. Não dá pra deixar o...</td>\n",
              "      <td>não gostei deste aparelho não dá pra deixar os...</td>\n",
              "      <td>24</td>\n",
              "      <td>gostei deste aparelho dá pra deixar aplicativo...</td>\n",
              "      <td>16</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9_159935</td>\n",
              "      <td>Muito ruim a adega acd 28 pois o compartimento...</td>\n",
              "      <td>muito ruim a adega acd  pois o compartimento i...</td>\n",
              "      <td>79</td>\n",
              "      <td>ruim adega acd pois compartimento inferior alt...</td>\n",
              "      <td>46</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>minus_1_393969</td>\n",
              "      <td>A tv LCD é muito boa e economiza espaço dentro...</td>\n",
              "      <td>a tv lcd é muito boa e economiza espaço dentro...</td>\n",
              "      <td>23</td>\n",
              "      <td>tv lcd boa economiza espaço dentro casa gostei...</td>\n",
              "      <td>13</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48c05fd4-11a4-480f-ab59-4ec43c27664c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-48c05fd4-11a4-480f-ab59-4ec43c27664c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-48c05fd4-11a4-480f-ab59-4ec43c27664c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Clean dataset and collect text statistics.\n",
        "reviews.dropna(subset=[\"review_text\"], inplace=True)\n",
        "reviews.loc[:, [\"review_text_cleaned\"]] = reviews[\"review_text\"].apply(\n",
        "    lambda x: clean_text(x)\n",
        ")\n",
        "\n",
        "reviews.loc[:, [\"review_text_cleaned_len\"]] = reviews[\"review_text_cleaned\"].apply(\n",
        "    count_word\n",
        ")\n",
        "reviews.loc[:, [\"review_text_cleaned_no_stopwords\"]] = reviews[\n",
        "    \"review_text_cleaned\"\n",
        "].apply(lambda x: \" \".join([word for word in x.split() if word not in (stopwords)]))\n",
        "\n",
        "reviews.loc[:, [\"review_text_cleaned_len_no_stopwords\"]] = reviews[\n",
        "    \"review_text_cleaned_no_stopwords\"\n",
        "].apply(count_word)\n",
        "\n",
        "# Replace the original polarity to -1 from 0, nan to 0.\n",
        "reviews_cleaned = reviews[\n",
        "    [\n",
        "        \"original_index\",\n",
        "        \"review_text\",\n",
        "        \"review_text_cleaned\",\n",
        "        \"review_text_cleaned_len\",\n",
        "        \"review_text_cleaned_no_stopwords\",\n",
        "        \"review_text_cleaned_len_no_stopwords\",\n",
        "        \"polarity\",\n",
        "    ]\n",
        "].copy()\n",
        "reviews_cleaned[\"polarity\"] = reviews_cleaned[\"polarity\"].replace({0: -1, np.nan: 0})\n",
        "reviews_cleaned[\"polarity\"] = reviews_cleaned[\"polarity\"].astype(int)\n",
        "#\n",
        "reviews_cleaned.dropna(subset=[\"review_text_cleaned_no_stopwords\"], inplace=True)\n",
        "reviews_cleaned.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorize dataset"
      ],
      "metadata": {
        "id": "n_b4vnzxQF7b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HGh1zm2FJ_tI"
      },
      "outputs": [],
      "source": [
        "reviews_train_dataset, reviews_test_dataset = train_test_split(\n",
        "    reviews_cleaned,\n",
        "    stratify=reviews_cleaned[\"polarity\"],\n",
        "    test_size=0.20,\n",
        "    random_state=rng,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mEFYlkmEJ_tI",
        "outputId": "2147afcd-a1b0-40ba-d8be-e3411e332902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cv vectorizer train matrix has 23560 rows and 52 columns\n",
            "The cv vectorizer test matrix has 5891 rows and 52 columns\n",
            "The tv vectorizer train matrix has 23560 rows and 52 columns\n",
            "The tv vectorizer test matrix has 5891 rows and 52 columns\n"
          ]
        }
      ],
      "source": [
        "# Counter vectorizer\n",
        "vectorizers = {\n",
        "    \"cv\": CountVectorizer(stop_words=stopwords, max_features=NUMBER_OF_WORDS),\n",
        "    \"tv\": TfidfVectorizer(stop_words=stopwords, max_features=NUMBER_OF_WORDS),\n",
        "}\n",
        "\n",
        "if not os.path.exists(DATA_PROCESSED_FOLDER):\n",
        "    os.makedirs(DATA_PROCESSED_FOLDER)\n",
        "\n",
        "for name, model in vectorizers.items():\n",
        "    reviews_train_vectorized, vocab = text_to_vector(model, reviews_train_dataset)\n",
        "    reviews_train_vectorized.to_pickle(os.path.join(DATA_PROCESSED_FOLDER, f\"buscape_reviews_train_dataset_{name}_s{NUMBER_OF_WORDS}.pkl\"))\n",
        "\n",
        "    reviews_test_vectorized, _ = text_to_vector(model, reviews_test_dataset)\n",
        "    reviews_test_vectorized.to_pickle(os.path.join(DATA_PROCESSED_FOLDER, f\"buscape_reviews_test_dataset_{name}_s{NUMBER_OF_WORDS}.pkl\"))\n",
        "    \n",
        "    print(\n",
        "        f\"The {name} vectorizer train matrix has {reviews_train_vectorized.shape[0]} rows and {reviews_train_vectorized.shape[1]} columns\"\n",
        "    )\n",
        "    print(\n",
        "        f\"The {name} vectorizer test matrix has {reviews_test_vectorized.shape[0]} rows and {reviews_test_vectorized.shape[1]} columns\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rZrbz__gJ_tJ",
        "outputId": "9c7742ec-b4ae-4c2e-c295-1a061841d658",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: word2vec_cbow_s50\n",
            "Downloading: word2vec_skip_s50\n",
            "Downloading: fasttext_cbow_s50\n",
            "Downloading: fasttext_skip_s50\n",
            "Downloading: glove_glove_s50\n",
            "Downloading: wang2vec_cbow_s50\n",
            "Downloading: wang2vec_skip_s50\n"
          ]
        }
      ],
      "source": [
        "# Download embeddings model.\n",
        "for model, architecture in EMBEDDING_NAMES:\n",
        "    download_extract(model, architecture)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO9AKmkGJ_tK"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trainned fast text embedding.\n",
        "logger.info(\"Load fast text embeddings.\")\n",
        "DATA_EMBEDDING_FOLDER=os.path.join(DATA_EMBEDDINGS_FOLDER, \"fasttext\")\n",
        "fasttext_cbow_s50 = KeyedVectors.load_word2vec_format(os.path.join(DATA_EMBEDDING_FOLDER, \"cbow_s50.txt\"))\n",
        "fasttext_skip_s50 = KeyedVectors.load_word2vec_format(os.path.join(DATA_EMBEDDING_FOLDER, \"skip_s50.txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07YZRPurJ_tK"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trainned glove embedding.\n",
        "logger.info(\"Load glove embeddings.\")\n",
        "DATA_EMBEDDING_FOLDER=os.path.join(DATA_EMBEDDINGS_FOLDER, \"glove\")\n",
        "glove_s50 = KeyedVectors.load_word2vec_format(os.path.join(DATA_EMBEDDING_FOLDER,\"glove_s50.txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oW8mkSKJ_tL"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trainned wang2vec embedding.\n",
        "logger.info(\"Load wang2vec embeddings.\")\n",
        "DATA_EMBEDDING_FOLDER=os.path.join(DATA_EMBEDDINGS_FOLDER, \"wang2vec\")\n",
        "wang2vec_cbow_s50 = KeyedVectors.load_word2vec_format(os.path.join(DATA_EMBEDDING_FOLDER, \"cbow_s50.txt\"))\n",
        "wang2vec_skip_s50 = KeyedVectors.load_word2vec_format(os.path.join(DATA_EMBEDDING_FOLDER, \"skip_s50.txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4kIn7gPJ_tM"
      },
      "outputs": [],
      "source": [
        "# Load the pre-trainned word2vec embedding.\n",
        "logger.info(\"Load word2vec embeddings.\")\n",
        "DATA_EMBEDDING_FOLDER=os.path.join(DATA_EMBEDDINGS_FOLDER, \"word2vec\")\n",
        "word2vec_cbow_s50 = KeyedVectors.load_word2vec_format(os.path.join(DATA_EMBEDDING_FOLDER, \"cbow_s50.txt\"))\n",
        "word2vec_skip_s50 = KeyedVectors.load_word2vec_format(os.path.join(DATA_EMBEDDING_FOLDER, \"skip_s50.txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P2Y1FCMJ_tM"
      },
      "outputs": [],
      "source": [
        "embedding_models = [fasttext_cbow_s50, fasttext_skip_s50, glove_s50,\n",
        "                    wang2vec_cbow_s50, wang2vec_skip_s50, word2vec_cbow_s50, word2vec_skip_s50]\n",
        "\n",
        "for name, model in zip(EMBEDDING_NAMES, embedding_models):\n",
        "    reviews_train_dtm = text_to_embedding(\n",
        "        reviews_train_dataset['review_text'], model, vectorizers[\"tv\"], vocab, 50)\n",
        "    reviews_train_processed = pd.concat([reviews_train_dataset.reset_index()[['original_index']], reviews_train_dtm.reset_index(\n",
        "        drop=True), reviews_train_dataset.reset_index()[['polarity']]], axis=1, ignore_index=True)\n",
        "    reviews_train_processed.to_pickle(\n",
        "        os.path.join(DATA_PROCESSED_FOLDER, f\"buscape_reviews_train_dataset_{name[0]}_{name[1]}.pkl\"))\n",
        "    logger.info(\n",
        "        f\"The {name} vectorized train dataframe has {reviews_train_processed.shape[0]} rows and {reviews_train_processed.shape[1]} columns\")\n",
        "\n",
        "    reviews_test_dtm = text_to_embedding(\n",
        "        reviews_test_dataset['review_text'], model, vectorizers[\"tv\"], vocab, 50)\n",
        "    reviews_test_processed = pd.concat([reviews_test_dataset.reset_index()[['original_index']], reviews_test_dtm.reset_index(\n",
        "        drop=True), reviews_test_dataset.reset_index()[['polarity']]], axis=1, ignore_index=True)\n",
        "    reviews_test_processed.to_pickle(\n",
        "        os.path.join(DATA_PROCESSED_FOLDER, f\"buscape_reviews_test_dataset_{name[0]}_{name[1]}.pkl\"))\n",
        "    logger.info(\n",
        "        f\"The {name} vectorized test dataframe has {reviews_test_processed.shape[0]} rows and {reviews_test_processed.shape[1]} columns\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcujluc2J_tN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel\n",
        "\n",
        "model = AutoModel.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
        "logging.info(f\"Transformers model class model: {type(model)}\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"neuralmind/bert-base-portuguese-cased\", do_lower_case=True\n",
        ")\n",
        "logging.info(f\"Transformers tokenizer class: {type(tokenizer)}\")\n",
        "\n",
        "\n",
        "# Create a function to tokenize a set of texts\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=sent,  # Preprocess sentence\n",
        "            add_special_tokens=True,     # Add `[CLS]` and `[SEP]`\n",
        "            max_length=64,               # Max length to truncate/pad\n",
        "            padding='max_length',        # Pad sentence to max length\n",
        "            truncation='only_first',     # Truncate sentence to max length\n",
        "            return_attention_mask=True,  # Return attention mask\n",
        "        )\n",
        "\n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get(\"input_ids\"))\n",
        "        attention_masks.append(encoded_sent.get(\"attention_mask\"))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "\n",
        "review_train_inputs, review_train_masks = preprocessing_for_bert(\n",
        "    list(reviews_train_dataset[\"review_text\"])\n",
        ")\n",
        "with torch.no_grad():\n",
        "    outs = model(review_train_inputs, review_train_masks)\n",
        "    review_train_bert_encoded = outs[0][:, 0, :]\n",
        "\n",
        "review_test_inputs, review_test_masks = preprocessing_for_bert(\n",
        "    list(reviews_test_dataset[\"review_text\"])\n",
        ")\n",
        "with torch.no_grad():\n",
        "    outs = model(review_test_inputs, review_test_masks)\n",
        "    review_test_bert_encoded = outs[0][:, 0, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rnpCCQwJ_tN"
      },
      "outputs": [],
      "source": [
        "reviews_train_processed_bert = pd.concat(\n",
        "    [\n",
        "        reviews_train_dataset[[\"original_index\"]],\n",
        "        review_train_bert_encoded,\n",
        "        reviews_train_dataset[[\"polarity\"]],\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "reviews_train_processed_bert.to_pickle(os.path.join(DATA_PROCESSED_FOLDER, \"buscape_reviews_train_dataset_bert.pkl\"))\n",
        "\n",
        "reviews_test_processed_bert = pd.concat(\n",
        "    [\n",
        "        reviews_test_dataset[[\"original_index\"]],\n",
        "        review_test_bert_encoded,\n",
        "        reviews_test_dataset[[\"polarity\"]],\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "reviews_test_processed_bert.to_pickle(os.path.join(DATA_PROCESSED_FOLDER,\"buscape_reviews_train_dataset_bert.pkl\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.8 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "6d8fcf32222123c2bc016e08cf8007b014ada14ae08852eb2d821271c6218457"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}