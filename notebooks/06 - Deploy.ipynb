{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/gomesluiz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2022-12-02 22:28:19,056 - Required packages installed.\n"
     ]
    }
   ],
   "source": [
    "# Required packages.\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import logging\n",
    "import string\n",
    "\n",
    "\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stopwords = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "\n",
    "RANDOM_SEED = 19730115\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "\n",
    "logging.basicConfig(format=\"%(asctime)s - %(message)s\", level=logging.INFO)\n",
    "logging.info(\"Required packages installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script constants.\n",
    "DATA_ROOT_FOLDER = os.path.join(\n",
    "    os.path.dirname(os.path.dirname(os.path.abspath(__name__))), \"data\"\n",
    ")\n",
    "DATA_PROCESSED_FOLDER = os.path.join(DATA_ROOT_FOLDER, \"processed\")\n",
    "URL_SOURCE = \"https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/data/raw/buscape.csv\"\n",
    "RANDOM_SEED = 19730115\n",
    "NUMBER_OF_WORDS = 50\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scripts Functions.\n",
    "def load_dataset(source) -> None:\n",
    "    \"\"\"Download data from a url.\n",
    "\n",
    "    Args:\n",
    "        source (str): source data file\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    return pd.read_csv(source)\n",
    "\n",
    "\n",
    "def load_stratify_dataset(path, stratify=False):\n",
    "    \"\"\"Get the data from csv file\n",
    "\n",
    "    Args:\n",
    "        path(str): the file complete path.\n",
    "\n",
    "    Returns:\n",
    "        dataframe: A pandas dataframe.\n",
    "    \"\"\"\n",
    "    dataset = pd.read_csv(path)\n",
    "\n",
    "    if stratify:\n",
    "        dataset = dataset.groupby(\"polarity\", group_keys=False).apply(\n",
    "            lambda x: x.sample(frac=0.4)\n",
    "        )\n",
    "        dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def word_counter(text):\n",
    "    \"\"\"Word counter.\"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Make text lowercase, remove text in square brackets, remove punctuation and\n",
    "        remove words containing numbers.\n",
    "\n",
    "    Args:\n",
    "        text(str): string text to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        A cleaned text\n",
    "\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(\"\\[.*?\\]\", \"\", text)\n",
    "    text = re.sub(\"[%s]\" % re.escape(string.punctuation), \"\", text)\n",
    "    text = re.sub(\"\\w*\\d\\w*\", \"\", text)\n",
    "    text = re.sub('[``\"\"...]', \"\", text)\n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 22:28:33,832 - Dataset loaded from https://raw.githubusercontent.com/gomesluiz/product-review-analytics/main/data/raw/buscape.csv.\n"
     ]
    }
   ],
   "source": [
    "reviews = load_dataset(URL_SOURCE)\n",
    "logging.info(f\"Dataset loaded from {URL_SOURCE}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5522/2667142545.py:3: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  reviews.loc[:, ['review_text_cleaned_len']] = reviews['review_text_cleaned'].apply(word_counter)\n",
      "/tmp/ipykernel_5522/2667142545.py:5: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  reviews.loc[:, ['review_text_cleaned_len_no_stopwords']] = reviews['review_text_cleaned_no_stopwords'].apply(word_counter)\n"
     ]
    }
   ],
   "source": [
    "reviews.dropna(subset=[\"review_text\"], inplace=True)\n",
    "reviews.loc[:, [\"review_text_cleaned\"]] = reviews[\"review_text\"].apply(\n",
    "    lambda x: clean_text(x)\n",
    ")\n",
    "reviews.loc[:, [\"review_text_cleaned_len\"]] = reviews[\"review_text_cleaned\"].apply(\n",
    "    word_counter\n",
    ")\n",
    "reviews.loc[:, [\"review_text_cleaned_no_stopwords\"]] = reviews[\n",
    "    \"review_text_cleaned\"\n",
    "].apply(lambda x: \" \".join([word for word in x.split() if word not in (stopwords)]))\n",
    "reviews.loc[:, [\"review_text_cleaned_len_no_stopwords\"]] = reviews[\n",
    "    \"review_text_cleaned_no_stopwords\"\n",
    "].apply(word_counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_text_cleaned</th>\n",
       "      <th>review_text_cleaned_len</th>\n",
       "      <th>review_text_cleaned_no_stopwords</th>\n",
       "      <th>review_text_cleaned_len_no_stopwords</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4_55516</td>\n",
       "      <td>Estou muito satisfeito, o visor é melhor do qu...</td>\n",
       "      <td>estou muito satisfeito o visor é melhor do que...</td>\n",
       "      <td>45</td>\n",
       "      <td>satisfeito visor melhor imaginava boas imagens...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>minus_1_105339</td>\n",
       "      <td>\"muito boa\\n\\nO que gostei: preco\\n\\nO que não...</td>\n",
       "      <td>muito boa  o que gostei preco  o que não goste...</td>\n",
       "      <td>12</td>\n",
       "      <td>boa gostei preco gostei poderia</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23_382139</td>\n",
       "      <td>Rápida, ótima qualidade de impressão e fácil d...</td>\n",
       "      <td>rápida ótima qualidade de impressão e fácil de...</td>\n",
       "      <td>37</td>\n",
       "      <td>rápida ótima qualidade impressão fácil usar pr...</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_446456</td>\n",
       "      <td>Produto de ótima qualidade em todos os quesito!</td>\n",
       "      <td>produto de ótima qualidade em todos os quesito</td>\n",
       "      <td>8</td>\n",
       "      <td>produto ótima qualidade todos quesito</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_11324</td>\n",
       "      <td>Precisava comprar uma tv compatível com meu dv...</td>\n",
       "      <td>precisava comprar uma tv compatível com meu dv...</td>\n",
       "      <td>38</td>\n",
       "      <td>precisava comprar tv compatível dvd esra melho...</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index                                        review_text  \\\n",
       "0         4_55516  Estou muito satisfeito, o visor é melhor do qu...   \n",
       "1  minus_1_105339  \"muito boa\\n\\nO que gostei: preco\\n\\nO que não...   \n",
       "2       23_382139  Rápida, ótima qualidade de impressão e fácil d...   \n",
       "3        2_446456    Produto de ótima qualidade em todos os quesito!   \n",
       "4         0_11324  Precisava comprar uma tv compatível com meu dv...   \n",
       "\n",
       "                                 review_text_cleaned  review_text_cleaned_len  \\\n",
       "0  estou muito satisfeito o visor é melhor do que...                       45   \n",
       "1  muito boa  o que gostei preco  o que não goste...                       12   \n",
       "2  rápida ótima qualidade de impressão e fácil de...                       37   \n",
       "3     produto de ótima qualidade em todos os quesito                        8   \n",
       "4  precisava comprar uma tv compatível com meu dv...                       38   \n",
       "\n",
       "                    review_text_cleaned_no_stopwords  \\\n",
       "0  satisfeito visor melhor imaginava boas imagens...   \n",
       "1                    boa gostei preco gostei poderia   \n",
       "2  rápida ótima qualidade impressão fácil usar pr...   \n",
       "3              produto ótima qualidade todos quesito   \n",
       "4  precisava comprar tv compatível dvd esra melho...   \n",
       "\n",
       "   review_text_cleaned_len_no_stopwords  polarity  \n",
       "0                                    25         1  \n",
       "1                                     5         1  \n",
       "2                                    22         1  \n",
       "3                                     5         1  \n",
       "4                                    17         1  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the original polarity to -1 from 0, nan to 0.\n",
    "reviews_cleaned = reviews[\n",
    "    [\n",
    "        \"original_index\",\n",
    "        \"review_text\",\n",
    "        \"review_text_cleaned\",\n",
    "        \"review_text_cleaned_len\",\n",
    "        \"review_text_cleaned_no_stopwords\",\n",
    "        \"review_text_cleaned_len_no_stopwords\",\n",
    "        \"polarity\",\n",
    "    ]\n",
    "].copy()\n",
    "reviews_cleaned[\"polarity\"] = reviews_cleaned[\"polarity\"].replace({0: -1, np.nan: 0})\n",
    "reviews_cleaned[\"polarity\"] = reviews_cleaned[\"polarity\"].astype(int)\n",
    "#\n",
    "reviews_cleaned.dropna(subset=[\"review_text_cleaned_no_stopwords\"], inplace=True)\n",
    "reviews_cleaned.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_cleaned_train, reviews_cleaned_test = train_test_split(\n",
    "    reviews_cleaned,\n",
    "    stratify=reviews_cleaned[\"polarity\"],\n",
    "    test_size=0.20,\n",
    "    random_state=rng,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_PROCESSED_FOLDER):\n",
    "    os.makedirs(DATA_PROCESSED_FOLDER)\n",
    "reviews_cleaned_train.to_csv(\n",
    "    os.path.join(DATA_PROCESSED_FOLDER, \"buscape_reviews_train_dataset.csv\"),\n",
    "    index=False,\n",
    ")\n",
    "reviews_cleaned_test.to_csv(\n",
    "    os.path.join(DATA_PROCESSED_FOLDER, \"buscape_reviews_test_dataset.csv\"), index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the reviews datasets.\n",
    "logging.info(\"Load the reviews datasets.\")\n",
    "reviews_train_dataset = load_stratify_dataset(\n",
    "    os.path.join(DATA_PROCESSED_FOLDER, \"buscape_reviews_train_dataset.csv\"), True\n",
    ")\n",
    "\n",
    "reviews_test_dataset = load_stratify_dataset(\n",
    "    os.path.join(DATA_PROCESSED_FOLDER, \"buscape_reviews_test_dataset.csv\", True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter vectorizer\n",
    "cv = CountVectorizer(stop_words=stopwords, max_features=NUMBER_OF_WORDS)\n",
    "reviews_train_cv = cv.fit_transform(\n",
    "    reviews_train_dataset['review_text_cleaned_no_stopwords'])\n",
    "reviews_train_dtm_cv = pd.DataFrame(\n",
    "    reviews_train_cv.toarray(), columns=cv.get_feature_names_out())\n",
    "reviews_train_dtm_cv.index = reviews_train_dataset.index\n",
    "reviews_train_processed_cv = pd.concat([reviews_train_dataset[[\n",
    "                                       'original_index']], reviews_train_dtm_cv, reviews_train_dataset[['polarity']]], axis=1)\n",
    "logging.info(\n",
    "    f\"The counter vectorizer train matrix has {reviews_train_processed_cv.shape[0]} rows and {reviews_train_processed_cv.shape[1]} columns\")\n",
    "\n",
    "reviews_test_cv = cv.transform(\n",
    "    reviews_test_dataset['review_text_cleaned_no_stopwords'])\n",
    "reviews_test_dtm_cv = pd.DataFrame(\n",
    "    reviews_test_cv.toarray(), columns=cv.get_feature_names_out())\n",
    "reviews_test_dtm_cv.index = reviews_test_dataset.index\n",
    "reviews_test_processed_cv = pd.concat([reviews_test_dataset[[\n",
    "                                      'original_index']], reviews_test_dtm_cv, reviews_test_dataset[['polarity']]], axis=1)\n",
    "logging.info(\n",
    "    f\"The counter vectorizer test matrix has {reviews_test_processed_cv.shape[0]} rows and {reviews_test_processed_cv.shape[1]} columns\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d8fcf32222123c2bc016e08cf8007b014ada14ae08852eb2d821271c6218457"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
